{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "from math import inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TensorFlow version: 2.10.0\n",
      " NumPy versio: 1.23.4\n"
     ]
    }
   ],
   "source": [
    "print(f' TensorFlow version: {tf.__version__}')\n",
    "print(f' NumPy versio: {np.__version__}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Algorithms implementation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utils"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "def dbscan(x):\n",
    "    x_list = x.tolist()\n",
    "    clustering = DBSCAN(eps=2).fit(x.reshape(-1, 1))\n",
    "    x_labels = clustering.labels_.tolist()\n",
    "    clusters = [set() for _ in range(max(x_labels)+1)]\n",
    "    print(clusters)\n",
    "    print(x_labels)\n",
    "    noice = set()\n",
    "    for i in range(len(x_list)):\n",
    "        if x_labels[i] == -1:\n",
    "            noice.add(x_list[i])\n",
    "        else:\n",
    "            clusters[x_labels[i]].add(x_list[i])\n",
    "    return clusters, noice"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stage 1 - Flow clustering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "def subset_of_sets(_set: set, sets):\n",
    "    return len([_ for s in sets if _set.issubset(s)]) > 0\n",
    "\n",
    "\n",
    "def tp_cluster(clusters: set, noise: set, tp_ratio: float, tp_deviation: float):\n",
    "    \"\"\"\n",
    "        Parameters\n",
    "        clusters : set\n",
    "            Set of DBSCAN cluster sets in descending throughput order\n",
    "        noise : set\n",
    "            Set of DBSCAN noice flows\n",
    "        tp_ratio : float\n",
    "            Ratio used to determine if two DBSCAN clusters can be combined into one TPCluster\n",
    "        tp_deviation : float\n",
    "            The relative distance a noise flow can be away from a TPCluster to be assigned to that cluster\n",
    "\n",
    "        Returns\n",
    "        cs : set\n",
    "            set of TPClusters\n",
    "    \"\"\"\n",
    "\n",
    "    r = 0\n",
    "    cs = set()\n",
    "    for cluster in clusters:\n",
    "        if not subset_of_sets(cluster, cs):\n",
    "            cs.add(cluster)\n",
    "            m = max(cluster)\n",
    "            for cluster_k in clusters:\n",
    "                if cluster_k is cluster: continue\n",
    "                m_prim = max(cluster_k)\n",
    "                if (1 - tp_ratio) * m < m_prim < m:\n",
    "                    cs[r] += cluster_k\n",
    "            r += 1\n",
    "    for n_j in noise:\n",
    "        delta_min = inf\n",
    "        a = None\n",
    "        for i in range(len(cs)):\n",
    "            m = max(cs[i])\n",
    "            if (-tp_deviation * m) <= (m - n_j) <= delta_min:\n",
    "                delta_min = m - n_j\n",
    "                a = i\n",
    "        if a:\n",
    "            cs[a] += n_j\n",
    "        else:\n",
    "            cs[0] += n_j\n",
    "    return cs\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stage 2 - FOF computation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "def compute_fof(cs):\n",
    "    \"\"\"\n",
    "        Parameters\n",
    "        clusters : set\n",
    "            Set of TPCluster sets\n",
    "\n",
    "        Returns:\n",
    "            FOF score for each flow in each cluster\n",
    "    \"\"\"\n",
    "    f = [[_ for _ in c_i] for c_i in range(len(cs))]\n",
    "    k = len(cs)\n",
    "    for i in range(k):\n",
    "        c_np = np.array(cs[i])\n",
    "        s_labels = KMeans(n_clusters=k).fit(c_np).labels_\n",
    "        s_count = max(s_labels) + 1\n",
    "        c_prim = 0\n",
    "        for s_i in range(s_count):\n",
    "            c_prim = max(c_prim, np.sum(c_np * (s_labels == s_i)) / np.sum(s_labels == s_i))\n",
    "        for j in range(len(cs[i])):\n",
    "            f[i][j] = np.abs(cs[i][j] - c_prim) / np.abs(c_prim)\n",
    "    return f\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[set(), set(), set()]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "([{8.88207201684526, 9.146816162940052, 10.084031945135939, 10.534275625039351, 9.801052694831732, 12.222264593884878, 10.5973661896395, 8.960964647171712, 9.262700356650672, 9.194451476084557}, {18.681823377792018, 19.993007689387323, 20.855915864460226, 19.967380782270233, 20.81909999115837, 21.61455636981925, 19.733090112459152, 21.808516765189367, 21.040357994853988, 20.194217769192708}, {28.940294082493203, 29.272453610623142, 29.027821176550827, 29.168874210128074, 29.98156195250162, 30.400773198174765, 31.702914621691463, 29.929637588582587, 30.685643257600322, 31.271522814556164}], set())\n"
     ]
    }
   ],
   "source": [
    "X1 = np.random.normal(10, 1, 10)\n",
    "X2 = np.random.normal(20, 1, 10)\n",
    "X3 = np.random.normal(30, 1, 10)\n",
    "X = np.concatenate((X1, X2, X3), axis=0)\n",
    "print(dbscan(X))\n",
    "# X_list = X.tolist()\n",
    "# X = X.reshape(-1, 1)\n",
    "# clustering = DBSCAN(eps=2).fit(X)\n",
    "# X_labels = clustering.labels_.tolist()\n",
    "# print(X_labels)\n",
    "# print(X_list)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.4463600567482\n"
     ]
    }
   ],
   "source": [
    "X = np.random.normal(10, 1, 10)\n",
    "k_means = KMeans(n_clusters=4).fit(X.reshape(-1, 1)).labels_\n",
    "print(np.sum(X * (k_means == 0)) / np.sum(k_means == 0))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
